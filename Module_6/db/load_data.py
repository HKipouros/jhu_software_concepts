"""
This module reads JSON data containing applicant details, creates (or resets) the
`applicants` table, and inserts the data into the table.

Intended to be run manually or used as a utility during data updates.

Environment Variables:
    DATABASE_URL (str): PostgreSQL connection string used to connect to the database.

Usage:
    python src/load_data.py

Input:
    JSON file (e.g., 'llm_extend_applicant_data.json') with a list of applicant entries.

Each entry should include:
    - program, comments, date_added, url, status, term, US/International,
      GPA, GRE, GRE_V, GRE_AW, Degree, llm-generated-program, llm-generated-university
"""

import os
import json
import sys
import psycopg
from pathlib import Path
from dotenv import load_dotenv

# Load environment variables from .env file (for local development)
# Look for .env in the project root directory
env_path = Path(__file__).parent.parent / '.env'
load_dotenv(dotenv_path=env_path)


def get_db_connection():
    """Create and return a database connection."""
    database_url = os.getenv("DATABASE_URL", "postgres://postgres:Potassiumtree43!@db:5432/gradcafe_db")

    return psycopg.connect(database_url)

def watermark():
    """Create a watermark table that ensures idempotent inserts."""
    create_query = """
        CREATE TABLE IF NOT EXISTS ingestion_watermarks (
            source TEXT PRIMARY KEY,
            last_seen TEXT, 
            updated_at TIMESTAMPTZ DEFAULT now()
        )
    """
    conn = get_db_connection()
    with conn.cursor() as cur:
        cur.execute(create_query)
    conn.commit()


def data_to_base(file_name: str):  # pylint: disable=R0914
    """
    Function to add applicant data from json file to database
    """
    conn = get_db_connection()
    try:
        # Create a cursor object and create "applicant" table.
        with conn.cursor() as cur:  # pylint: disable=E1101

            # Drop table if exists, statement and execution separated.
            drop_table_query = psycopg.sql.SQL("DROP TABLE IF EXISTS {table}").format(
                table=psycopg.sql.Identifier("applicants")
            )
            cur.execute(drop_table_query)

            # Create table if needed, statement and execution separated.
            create_table_query = psycopg.sql.SQL("""
                CREATE TABLE IF NOT EXISTS {table} (
                    id int GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
                    program TEXT,
                    comments TEXT,
                    date_added date,
                    url TEXT UNIQUE,
                    status TEXT,
                    term TEXT,
                    us_or_international TEXT,
                    gpa real,
                    gre real,
                    gre_v real,
                    gre_aw real,
                    degree TEXT,
                    llm_generated_program TEXT,
                    llm_generated_university TEXT
                )
            """).format(
                table=psycopg.sql.Identifier("applicants")
            )
            cur.execute(create_table_query)

            # Load json data.
            with open(file_name, 'r', encoding="utf-8") as fhand:
                data = json.load(fhand)

            # Prepare data for insertion.
            columns = [
                "program", "comments", "date_added", "url", "status", "term", 
                "us_or_international", "gpa", "gre", "gre_v", "gre_aw", "degree",
                "llm_generated_program", "llm_generated_university"
            ]

            # Build the SQL insert query using sql.Identifier and sql.Placeholder.
            insert_query = psycopg.sql.SQL("""
                INSERT INTO {table} ({fields})
                VALUES ({placeholders})
                ON CONFLICT (url) DO NOTHING
            """).format(
                table=psycopg.sql.Identifier("applicants"),
                fields=psycopg.sql.SQL(", ").join(psycopg.sql.Identifier(col) for col in columns),
                placeholders=psycopg.sql.SQL(", ").join(psycopg.sql.Placeholder() for _ in columns)
            )

            # Insert each entry.
            for entry in data:
                values = (
                    entry.get("program") or None,
                    entry.get("comments") or None,
                    entry.get("date_added") or None,
                    entry.get("url") or None,
                    entry.get("status") or None,
                    entry.get("term") or None,
                    entry.get("US/International") or None,
                    float(entry["GPA"]) if entry.get("GPA") else None,
                    float(entry["GRE"]) if entry.get("GRE") else None,
                    float(entry["GRE_V"]) if entry.get("GRE_V") else None,
                    float(entry["GRE_AW"]) if entry.get("GRE_AW") else None,
                    entry.get("Degree") or None,
                    entry.get("llm-generated-program") or None,
                    entry.get("llm-generated-university") or None
                )

                cur.execute(insert_query, values)

            # Commit the changes to the database.
            conn.commit()  # pylint: disable=E1101
    finally:
        # Close the connection.
        conn.close()  # pylint: disable=E1101


if __name__ == "__main__":
    # Get the path to the JSON file in the same directory as this script
    script_dir = Path(__file__).parent
    INPUT_FILE = "applicant_data.json"
    data_to_base(str(INPUT_FILE))
    print("Done!!")
