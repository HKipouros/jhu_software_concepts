Name: Holly Kipouros (hkipour1)
Module Info: Module 2: Web Scraping due 09/07/2025 at 11:59 PM EST
Approach: 

SSH url to GitHub repo -  git@github.com:HKipouros/jhu_software_concepts.git


Preliminary - I checked robots.txt from TheGradCafe and verified that the url path I plan to scrape (https://www.thegradcafe.com/survey/) was allowed, and verified that I was not using any disallowed agents. I then inspected https://www.thegradcafe.com/survey/ using Developer Tools to examine the html structure.

scrape.py - The program begins by defining the function scrape_data(), which takes in one argument (a number of data points to scrape) and returns a list of dictionary data corresponding to the data points. The function begins by using urllib3 to open a webpage containing applicant data from TheGradCafe using a try/except structure to catch errors opening the page. Then, a BeautifulSoup object is generated to interact with the HTML. The “soup” object is narrowed down to the “tbody” tag as I saw from inspection that this section contains the pertinent applicant data. The function then iterates through “tr” tags and extracts the text, assigning the extracted text as entries in a dictionary called “entry” (the data of each applicant, such as school, degree, etc., represents one “entry”). Some but not all applicants provided extra data such as comments and testing scores, and the program checks for the presence of these using an if/else structure.  Ultimately all dictionaries are collected in a list called “entries”. The program also includes the function save_data() which saves the scraped data into a json file using the json.dumps() method. This function takes in the data generated by scrape_data() as an input, and also takes in a string corresponding to the name of the file where the data is saved. The program concludes with code to run each function embedded in a dunder main block. Within this block the number of data points to collect is specified (30,000 for this assignment).

clean.py - This program begins by defining a load_data() function, which takes a json file such as that generated by scrape.py and returns data from the json as a Python object. Next, the clean_data() function takes in data and performs cleaning operations. These include using a Regex patterns to remove numbers from school name data, remove html tags, and convert semester data to a standard format, as I noticed that older applicant data listed the semester as e.g. “F18” instead of “Fall 2018”. Finally, the function returns a formatted data structure matching the format in the assignment brief and including cleaned up data. The program also includes the save_clean_data() function which saves the cleaned up data as a json such that it can be further processed by the large language model code provided by the assignment. Finally, the program runs load_data(), clean_data(), and save_clean_data() on the output from scrape.py within a dunder main block, resulting in the cleaned data being saved as “applicant_data.json” such that it can be further processed by the LLM provided by the assignment.

Post-processing - To further process the data using the LLM provided by the assignment, I ran “export MODEL_FILE=tinyllama-1.1b-chat-v1.0.Q3_K_M.gguf python app.py –file applicant_data.json” from the shell in Replit and saved the output as “llm_extend_applicant_data.json”.

“Edge cases” I came across during processing with the LLM -
Entry 986392 listed their program as “tamanna.nstu99@gmail.com” which is understood to be the applicant mis-entering data into the program field. The LLM output left the field as-is. 

Entry 986386 listed their program as “RonaldAnoms” which is understood to be the applicant mis-entering data into the program field. The LLM classed this program as “Royal Anomalies”. 

Entry 934710 listed their program as “PhD Philosoph” which is understood to be Philosophy. The LLM output left the field as-is. 

Entry 793338 listed their program and school as “Computer Science + Statistics ( Joint ), Purdue University”. This format is a little unusual and the LLM didn’t parse out the school. The LLM generated program output was “Computer Science + Statistics ( Joint ), Purdue University"

Known bugs- there are no known bugs.